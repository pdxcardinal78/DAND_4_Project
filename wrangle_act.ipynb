{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages needed to gather, clean, \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tweepy\n",
    "import json\n",
    "import glob\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "* Import the weratedogs csv file into a dataframe\n",
    "\n",
    "* Download udacity image predictor file from the the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "\n",
    "* Create a json file containing each tweet's retweet count and favorite (\"like\") count at minimum, and any additional data you find interesting. Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt file. Each tweet's JSON data should be written to its own line. Then read this .txt file line by line into a pandas DataFrame with (at minimum) tweet ID, retweet count, and favorite count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      "tweet_id                      2356 non-null int64\n",
      "in_reply_to_status_id         78 non-null float64\n",
      "in_reply_to_user_id           78 non-null float64\n",
      "timestamp                     2356 non-null object\n",
      "source                        2356 non-null object\n",
      "text                          2356 non-null object\n",
      "retweeted_status_id           181 non-null float64\n",
      "retweeted_status_user_id      181 non-null float64\n",
      "retweeted_status_timestamp    181 non-null object\n",
      "expanded_urls                 2297 non-null object\n",
      "rating_numerator              2356 non-null int64\n",
      "rating_denominator            2356 non-null int64\n",
      "name                          2356 non-null object\n",
      "doggo                         2356 non-null object\n",
      "floofer                       2356 non-null object\n",
      "pupper                        2356 non-null object\n",
      "puppo                         2356 non-null object\n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_ta = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "df_ta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a request to pull the image predictions tsv file from the udacity site. Take the image predictions file thats stored in\n",
    "# check response status to ensure we don't have an error.\n",
    "# the response output and open a tsv file to hold the data so it can be called later.\n",
    "r = requests.get('https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv')\n",
    "r.raise_for_status()\n",
    "\n",
    "with open('image_predictions.tsv', 'wb') as handle:\n",
    "    for block in r.iter_content(1024):\n",
    "        handle.write(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for the image predictions\n",
    "df_pred = pd.read_csv('image_predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 630\n",
      "Rate limit reached. Sleeping for: 714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "# Pull information on tweets using twitter api\n",
    "# Pause loop to allow refresh of data pulling\n",
    "# print twitter tweet json data to file\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_token, consumer_token_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "i = 0\n",
    "df_error = []\n",
    "with open('tweet_json.txt', 'w') as append:\n",
    "    for index, row in df.iterrows():\n",
    "            try:\n",
    "                tweet = api.get_status(row['tweet_id'], )\n",
    "                json.dump(tweet._json, append)\n",
    "                append.write('\\n')\n",
    "            except tweepy.TweepError as e:\n",
    "                df_error.append({'tweet_id': row['tweet_id'], 'Error': (e.args[0][0]['code'], e.args[0][0]['message'])})\n",
    "                i = i+1\n",
    "                pass\n",
    "            \n",
    "df_error = pd.DataFrame(df_error, columns = ['tweet_id', 'Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through tweet_json file and extract the tweeet_id, retweet count, likes\n",
    "df_tweet_likes = []\n",
    "tweet_file = open('tweet_json.txt')\n",
    "for line in tweet_file:\n",
    "    text = line.split()\n",
    "    data = json.loads(''.join(text))\n",
    "    tweet_id = data['id']\n",
    "    retweet_count = data['retweet_count']\n",
    "    favorite_count = data['favorite_count']\n",
    "    df_tweet_likes.append({'tweet_id' : tweet_id\n",
    "                          ,'favorite_count' : favorite_count\n",
    "                          ,'retweet_count' : retweet_count})\n",
    "\n",
    "df_tweet_likes = pd.DataFrame(df_tweet_likes, columns = ['tweet_id', 'favorite_count', 'retweet_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality\n",
    "Review each table and find the quality issues\n",
    "i.e. Data formats, typos, data inconsistencies (abbr vs. full length), missing information, missing records\n",
    "\n",
    "#### Tidiness\n",
    "Breaking apart data in columns (email/phone), dog classification(pupper, doggo, ect), table structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      "tweet_id                      2356 non-null int64\n",
      "in_reply_to_status_id         78 non-null float64\n",
      "in_reply_to_user_id           78 non-null float64\n",
      "timestamp                     2356 non-null object\n",
      "source                        2356 non-null object\n",
      "text                          2356 non-null object\n",
      "retweeted_status_id           181 non-null float64\n",
      "retweeted_status_user_id      181 non-null float64\n",
      "retweeted_status_timestamp    181 non-null object\n",
      "expanded_urls                 2297 non-null object\n",
      "rating_numerator              2356 non-null int64\n",
      "rating_denominator            2356 non-null int64\n",
      "name                          2356 non-null object\n",
      "doggo                         2356 non-null object\n",
      "floofer                       2356 non-null object\n",
      "pupper                        2356 non-null object\n",
      "puppo                         2356 non-null object\n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_ta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
